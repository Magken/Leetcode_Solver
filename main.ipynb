{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Creating working directory\n",
    "\n",
    "Creates Directories and looks for windows on all desktops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected 15 windows (potential desktops):\n",
      "1. ‚óè main.ipynb - Leetcode_Solver - Visual Studio Code (Width: 1936, Height: 1056)\n",
      "2. ChatGPT - Leet code solver - Google Chrome (Width: 1936, Height: 1056)\n",
      "3. wf1.ipynb - Ontology_V2 - Visual Studio Code (Width: 1200, Height: 800)\n",
      "4. (31) Jon Stewart on Trump's Botched Tariff Rollout & The Stock Market's Meltdown | The Daily Show - YouTube - Google Chrome (Width: 1936, Height: 1056)\n",
      "5. League of Legends (Width: 1024, Height: 576)\n",
      "6. m17fu - Search and 1 more page - Work - Microsoft‚Äã Edge (Width: 1936, Height: 1056)\n",
      "7. Calculator (Width: 336, Height: 540)\n",
      "8. Settings (Width: 1920, Height: 1040)\n",
      "9.  (Width: 1920, Height: 1040)\n",
      "10.  (Width: 1920, Height: 1040)\n",
      "11. NVIDIA GeForce Overlay (Width: 1920, Height: 1080)\n",
      "12. Microsoft Text Input Application (Width: 1920, Height: 1080)\n",
      "13.  (Width: 3840, Height: 1080)\n",
      "14.  (Width: 3840, Height: 1080)\n",
      "15. Program Manager (Width: 3840, Height: 1080)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Imports\n",
    "import os\n",
    "import pygetwindow as gw\n",
    "import pyautogui\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\"\n",
    "\n",
    "\n",
    "# Optional: Set tesseract path if needed\n",
    "# pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "\n",
    "# Step 2: Create output folder if not exists\n",
    "output_dir = \"parsed_texts\"\n",
    "output_dir2 = \"explained_solns\"\n",
    "output_dir3 = \"screen_shots\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(output_dir2, exist_ok=True)\n",
    "os.makedirs(output_dir3, exist_ok=True)\n",
    "\n",
    "# Step 3: Detect desktop windows\n",
    "\n",
    "windows = gw.getWindowsWithTitle(\"\")  # all windows\n",
    "\n",
    "# Filter out minimized or tiny windows\n",
    "desktop_windows = [win for win in windows if not win.isMinimized and win.width > 100 and win.height > 100]\n",
    "\n",
    "print(f\"Detected {len(desktop_windows)} windows (potential desktops):\")\n",
    "for i, win in enumerate(desktop_windows):\n",
    "    print(f\"{i+1}. {win.title} (Width: {win.width}, Height: {win.height})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose Window and Screenshot, With Ocr parse and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Screenshot saved to: screen_shots\\screenshot_20250410_021703.png\n",
      "üìù Parsed text saved to: parsed_texts\\parsed_text_20250410_021703.txt\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageEnhance\n",
    "\n",
    "index_to_use = 1  # Change this to select a different window\n",
    "\n",
    "# Define output directories\n",
    "screenshot_dir = \"screen_shots\"\n",
    "parsed_text_dir = \"parsed_texts\"\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(screenshot_dir, exist_ok=True)\n",
    "os.makedirs(parsed_text_dir, exist_ok=True)\n",
    "\n",
    "if len(desktop_windows) > index_to_use:\n",
    "    target_window = desktop_windows[index_to_use]\n",
    "    target_window.activate()\n",
    "    time.sleep(1)  # Allow the window to focus\n",
    "\n",
    "    bbox = (target_window.left, target_window.top, target_window.width, target_window.height)\n",
    "\n",
    "    # Take screenshot\n",
    "    screenshot = pyautogui.screenshot(region=bbox)\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    image_path = os.path.join(screenshot_dir, f\"screenshot_{timestamp}.png\")\n",
    "    screenshot.save(image_path)\n",
    "\n",
    "    # === OCR Section ===\n",
    "\n",
    "    # Load and upscale the image (2x)\n",
    "    zoom_int = 4\n",
    "    image = Image.open(image_path)\n",
    "    upscaled_image = image.resize((image.width * zoom_int, image.height * zoom_int), Image.LANCZOS)\n",
    "\n",
    "    # Optional: Enhance contrast (can be adjusted or commented out)\n",
    "    # enhancer = ImageEnhance.Contrast(upscaled_image)\n",
    "    # upscaled_image = enhancer.enhance(2.0)\n",
    "\n",
    "    # Run OCR with custom config\n",
    "    custom_config = r'--oem 3 --psm 6'\n",
    "    parsed_text = pytesseract.image_to_string(upscaled_image, config=custom_config)\n",
    "\n",
    "    # Save parsed text\n",
    "    text_path = os.path.join(parsed_text_dir, f\"parsed_text_{timestamp}.txt\")\n",
    "    with open(text_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(parsed_text)\n",
    "\n",
    "    print(f\"‚úÖ Screenshot saved to: {image_path}\")\n",
    "    print(f\"üìù Parsed text saved to: {text_path}\")\n",
    "else:\n",
    "    print(f\"‚ùå Not enough windows. Index {index_to_use} is out of range.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT API Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† GPT Response:\n",
      "\n",
      "### Problem: Group Anagrams (LeetCode #49)\n",
      "\n",
      "#### Description:\n",
      "Given an array of strings `strs`, group the anagrams together. You can return the answer in any order.\n",
      "\n",
      "An anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once.\n",
      "\n",
      "#### Example:\n",
      "**Input:** `strs = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]`  \n",
      "**Output:** `[[\"bat\"], [\"nat\", \"tan\"], [\"ate\", \"eat\", \"tea\"]]`\n",
      "\n",
      "#### Constraints:\n",
      "- `1 <= strs.length <= 10^4`\n",
      "- `1 <= strs[i].length <= 100`\n",
      "- `strs[i]` consists of lowercase English letters.\n",
      "\n",
      "### Thought Process:\n",
      "1. **Understanding Anagrams**: Two strings are anagrams if they contain the same characters with the same frequency. For instance, \"eat\" and \"tea\" are anagrams because they both consist of the letters 'e', 'a', and 't'.\n",
      "\n",
      "2. **Grouping Logic**: To group anagrams, we can use a hash table (or dictionary) where the key is a representation of the anagram group (such as a sorted version of the string) and the value is a list of strings (anagrams) that match that key.\n",
      "\n",
      "3. **Steps to Solve**:\n",
      "   - Initialize a dictionary to hold lists of anagrams.\n",
      "   - For each string in the input list, sort the string to create a key.\n",
      "   - Use this key to append the original string to the corresponding list in the dictionary.\n",
      "   - Finally, return the values (groups of anagrams) from the dictionary.\n",
      "\n",
      "### Complete Solution in Python:\n",
      "\n",
      "```python\n",
      "def groupAnagrams(strs):\n",
      "    anagrams = {}\n",
      "    \n",
      "    for s in strs:\n",
      "        # Sort the string to use it as a key\n",
      "        key = ''.join(sorted(s))\n",
      "        \n",
      "        # Append the original string to the corresponding list in the dictionary\n",
      "        if key not in anagrams:\n",
      "            anagrams[key] = []\n",
      "        anagrams[key].append(s)\n",
      "    \n",
      "    # Return the values of the dictionary as a list of lists\n",
      "    return list(anagrams.values())\n",
      "\n",
      "# Example usage:\n",
      "strs = [\"eat\", \"tea\", \"tan\", \"ate\", \"nat\", \"bat\"]\n",
      "output = groupAnagrams(strs)\n",
      "print(output)\n",
      "```\n",
      "\n",
      "### Explanation of the Code:\n",
      "1. We define a function `groupAnagrams` that takes a list of strings `strs`.\n",
      "2. We create a dictionary `anagrams` to hold the grouped anagrams.\n",
      "3. We iterate over each string `s` in `strs`, sort it, and use the sorted string as a key.\n",
      "4. If the key does not exist in the dictionary, we initialize it with an empty list.\n",
      "5. We append the original string `s` to the list corresponding to its sorted key.\n",
      "6. Finally, we return the values of the dictionary, which are the grouped anagrams.\n",
      "\n",
      "### Complexity Analysis:\n",
      "- **Time Complexity**: O(N * K log K), where:\n",
      "  - N is the number of strings in the input array.\n",
      "  - K is the maximum length of a string (for sorting).\n",
      "  \n",
      "- **Space Complexity**: O(N * K) in the worst case for the storage of the grouped anagrams.\n",
      "‚úÖ Solution saved to: explained_solns\\solution_20250410_022053.md\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Load API key from .env\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "# Directory for parsed text and solution output\n",
    "parsed_text_dir = \"parsed_texts\"\n",
    "explained_solns_dir = \"explained_solns\"\n",
    "os.makedirs(explained_solns_dir, exist_ok=True)\n",
    "\n",
    "# Get latest parsed text file\n",
    "parsed_text_files = sorted(os.listdir(parsed_text_dir), reverse=True)\n",
    "latest_text_file = next((f for f in parsed_text_files if f.endswith('.txt')), None)\n",
    "\n",
    "if latest_text_file:\n",
    "    with open(os.path.join(parsed_text_dir, latest_text_file), 'r', encoding='utf-8') as f:\n",
    "        parsed_text = f.read()\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an expert competitive programmer. In the provided text, \"\n",
    "        \"there is a LeetCode-style coding question. Your job is to extract the problem, \"\n",
    "        \"explain the logic step-by-step, and provide a full working solution, Giving the On time and space analysis. Your answer should be in python.\"\n",
    "    )\n",
    "\n",
    "    user_prompt = (\n",
    "        f\"Here is the parsed content from a screenshot:\\n\\n\"\n",
    "        f\"{parsed_text}\\n\\n\"\n",
    "        \"Please extract the coding question (if any), explain your thought process clearly, \"\n",
    "        \"and provide a complete answer with code.\"\n",
    "    )\n",
    "\n",
    "    # Submit to OpenAI using latest SDK format\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "        max_tokens=10000\n",
    "    )\n",
    "\n",
    "    # Extract and print response\n",
    "    gpt_response = completion.choices[0].message.content\n",
    "    print(\"üß† GPT Response:\\n\")\n",
    "    print(gpt_response)\n",
    "\n",
    "    # Save as Markdown file\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    md_path = os.path.join(explained_solns_dir, f\"solution_{timestamp}.md\")\n",
    "    with open(md_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(gpt_response)\n",
    "\n",
    "    print(f\"‚úÖ Solution saved to: {md_path}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No parsed text file found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
